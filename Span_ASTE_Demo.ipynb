{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raym2828/Span-ASTE/blob/main/Span_ASTE_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izKXA4b6-oIv",
        "outputId": "d57c7dab-d752-42f4-9707-2242760ce888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Span-ASTE'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 194 (delta 60), reused 77 (delta 46), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (194/194), 626.91 KiB | 927.00 KiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Note: switching to 'f53ec3c'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at f53ec3c Add command-line scoring instructions in README.md\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Cython==0.29.21\n",
            "  Downloading Cython-0.29.21-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PYEVALB==0.1.3\n",
            "  Downloading PYEVALB-0.1.3-py3-none-any.whl (13 kB)\n",
            "Collecting allennlp-models==1.2.2\n",
            "  Downloading allennlp_models-1.2.2-py3-none-any.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.7/353.7 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting allennlp==1.2.2\n",
            "  Downloading allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.1/505.1 KB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.19.46\n",
            "  Downloading botocore-1.19.46-py2.py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire==0.3.1\n",
            "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nltk==3.6.6\n",
            "  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.6.2\n",
            "  Downloading pydantic-1.6.2-cp38-cp38-manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3==1.16.46\n",
            "  Downloading boto3-1.16.46-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter>=0.10.2\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu==4.2.1\n",
            "  Downloading conllu-4.2.1-py2.py3-none-any.whl (14 kB)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.8/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.25.1)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<2.4,>=2.1.0\n",
            "  Downloading spacy-2.3.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.6/593.6 KB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.8/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.64.1)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.6.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.19.6)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.8/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (57.4.0)\n",
            "Collecting mbstrdecoder<2,>=1.0.0\n",
            "  Downloading mbstrdecoder-1.1.2-py3-none-any.whl (7.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5\n",
            "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
            "Collecting tabledata<2,>=1.3.0\n",
            "  Downloading tabledata-1.3.1-py3-none-any.whl (11 kB)\n",
            "Collecting typepy[datetime]<2,>=1.2.0\n",
            "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
            "Collecting DataProperty<2,>=0.55.0\n",
            "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.10.1)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.7)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.9)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 KB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.8)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.6)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (9.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (22.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n",
            "Building wheels for collected packages: fire, overrides, jsonnet, word2number, sacremoses\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111023 sha256=a0790a1c3d943e9bdf33b53eb041268d54f5be2286642f9b5fb6483ba523f370\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/a0/e2/7c4d0cd36f74f5ca64306f2553b3438af7d158e359a17e8382\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=591fbcf891346491ccd9abd38005705f91da6af4f269f9e493cd07ea15845f26\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/4f/72/28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp38-cp38-linux_x86_64.whl size=6332969 sha256=af190a88109762a5b42f6dbaa1f4be911f5cd988167f369cc2af61451eb3e5d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/ec/56/de861aae102c449ade2378772abbf9eb7e9acfe9a80f3e6036\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=d3574fa0832aa509b322a89bb2c6cd4fa0059f589ec09858e0233fa1298e32ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/f3/5a/d88198fdeb46781ddd7e7f2653061af83e7adb2a076d8886d6\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=16d87932173bee01c675bdb09ce37f95105ba050f432b0466285912ff9265933\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built fire overrides jsonnet word2number sacremoses\n",
            "Installing collected packages: word2number, tokenizers, sentencepiece, py-rouge, plac, overrides, jsonnet, filelock, dataclasses, conllu, urllib3, tcolorpy, srsly, sacremoses, pydantic, pathvalidate, numpy, nltk, mbstrdecoder, jsonpickle, jmespath, ftfy, fire, Cython, catalogue, typepy, torch, tensorboardX, pandas, botocore, transformers, torchvision, thinc, scikit-learn, s3transfer, spacy, DataProperty, boto3, tabledata, allennlp, pytablewriter, allennlp-models, PYEVALB\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.9.0\n",
            "    Uninstalling filelock-3.9.0:\n",
            "      Successfully uninstalled filelock-3.9.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.4\n",
            "    Uninstalling pydantic-1.10.4:\n",
            "      Successfully uninstalled pydantic-1.10.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.33\n",
            "    Uninstalling Cython-0.29.33:\n",
            "      Successfully uninstalled Cython-0.29.33\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.7\n",
            "    Uninstalling thinc-8.1.7:\n",
            "      Successfully uninstalled thinc-8.1.7\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.5 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "fastai 2.7.11 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.9 which is incompatible.\n",
            "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.6.2 which is incompatible.\n",
            "confection 0.0.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-0.29.21 DataProperty-0.55.0 PYEVALB-0.1.3 allennlp-1.2.2 allennlp-models-1.2.2 boto3-1.16.46 botocore-1.19.46 catalogue-1.0.2 conllu-4.2.1 dataclasses-0.6 filelock-3.0.12 fire-0.3.1 ftfy-6.1.1 jmespath-0.10.0 jsonnet-0.19.1 jsonpickle-3.0.1 mbstrdecoder-1.1.2 nltk-3.6.6 numpy-1.21.5 overrides-3.1.0 pandas-1.1.5 pathvalidate-2.5.2 plac-1.1.3 py-rouge-1.1 pydantic-1.6.2 pytablewriter-0.64.2 s3transfer-0.3.7 sacremoses-0.0.53 scikit-learn-0.22.2.post1 sentencepiece-0.1.97 spacy-2.3.9 srsly-1.0.6 tabledata-1.3.1 tcolorpy-0.1.2 tensorboardX-2.6 thinc-7.4.6 tokenizers-0.9.2 torch-1.7.0 torchvision-0.8.1 transformers-3.4.0 typepy-1.3.0 urllib3-1.26.14 word2number-1.1\n",
            "Found existing installation: dataclasses 0.6\n",
            "Uninstalling dataclasses-0.6:\n",
            "  Successfully uninstalled dataclasses-0.6\n",
            "Archive:  data.zip\n",
            "   creating: aste/data/\n",
            "   creating: aste/data/triplet_data/\n",
            "   creating: aste/data/triplet_data/14lap/\n",
            "  inflating: aste/data/triplet_data/14lap/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/test.txt  \n",
            "  inflating: aste/data/triplet_data/14lap/train.txt  \n",
            "   creating: aste/data/triplet_data/14res/\n",
            "  inflating: aste/data/triplet_data/14res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/14res/test.txt  \n",
            "  inflating: aste/data/triplet_data/14res/train.txt  \n",
            "   creating: aste/data/triplet_data/15res/\n",
            "  inflating: aste/data/triplet_data/15res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/15res/test.txt  \n",
            "  inflating: aste/data/triplet_data/15res/train.txt  \n",
            "   creating: aste/data/triplet_data/16res/\n",
            "  inflating: aste/data/triplet_data/16res/dev.txt  \n",
            "  inflating: aste/data/triplet_data/16res/test.txt  \n",
            "  inflating: aste/data/triplet_data/16res/train.txt  \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
        "!cd Span-ASTE && git checkout f53ec3c\n",
        "!cp -a Span-ASTE/* .\n",
        "!echo boto3==1.16.46 >> requirements.txt\n",
        "!bash setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "elrYAit7fP8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pTnCgDxcSQ5",
        "outputId": "1ec0a7c4-9c99-409d-8a8b-6b75638c03bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
            "target: (16, 17)\n",
            "opinion: (15, 15)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
            "target: (4, 4)\n",
            "opinion: (3, 3)\n",
            "label: LabelEnum.positive\n",
            "target: (9, 9)\n",
            "opinion: (8, 8)\n",
            "label: LabelEnum.positive\n",
            "target: (26, 26)\n",
            "opinion: (25, 25)\n",
            "label: LabelEnum.positive\n",
            "target: (31, 31)\n",
            "opinion: (29, 29)\n",
            "label: LabelEnum.positive\n",
            "\n",
            "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
            "target: (2, 3)\n",
            "opinion: (0, 0)\n",
            "label: LabelEnum.positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Data Exploration\n",
        "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from data_utils import Data\n",
        "\n",
        "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "data = Data.load_from_full_path(path)\n",
        "\n",
        "for s in data.sentences[:3]:\n",
        "    print(\"tokens:\", s.tokens)\n",
        "    for t in s.triples:\n",
        "        print(\"target:\", (t.t_start, t.t_end))\n",
        "        print(\"opinion:\", (t.o_start, t.o_end))\n",
        "        print(\"label:\", t.label)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained SpanModel weights\n",
        "from pathlib import Path\n",
        "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
        "url = template.format(data_name)\n",
        "model_tar = Path(url).name\n",
        "model_dir = Path(url).stem\n",
        "\n",
        "!wget -nc $url\n",
        "!tar -xf $model_tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LmrJekiPHpQ",
        "outputId": "a558ad86-7806-4208-d2ec-cb42aca74d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-20 00:29:22--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/14lap.tar\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230220T002923Z&X-Amz-Expires=300&X-Amz-Signature=41a4e28f61f3da79d7f897cbd23f7144deb611aace8443c4113b95c63436c4f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-02-20 00:29:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230220T002923Z&X-Amz-Expires=300&X-Amz-Signature=41a4e28f61f3da79d7f897cbd23f7144deb611aace8443c4113b95c63436c4f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409068544 (390M) [application/octet-stream]\n",
            "Saving to: ‘14lap.tar’\n",
            "\n",
            "14lap.tar           100%[===================>] 390.12M  3.97MB/s    in 2m 8s   \n",
            "\n",
            "2023-02-20 00:31:32 (3.05 MB/s) - ‘14lap.tar’ saved [409068544/409068544]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "b3bf1419586a48e1983006db8208c2ee",
            "b2964524130442869889ae7d4b66cbde",
            "fe16020d5dd44eee9c31f35dbcbbb121",
            "ea885b58cd6f4dada54fa30787c1c6ca",
            "068f7a5d5f124ef289ea37d778909b56",
            "71315cce26594e529e387c0f4106fca6",
            "7d8159fb6e1b4eed9064bd27b00cb167",
            "36cd33348e4e43e197142e37b0be18b7",
            "7630128ce13c4bb7bc32015deee09ba9",
            "fa655d553e6440c8b21c4935dd0d6a1c",
            "c59edc717c184afd8e32e39f5578ba09",
            "a0a2f566eb8947b7aec4906e76e97e2a",
            "05943317ad6548cd80b4ff1b335b77fa",
            "10256154352b4d3ca51e60bb807646ab",
            "cf8bfe8d68334a8fac6a57ee6b61a0c0",
            "32a6466b31eb4782a25cbc1195c8fb2d",
            "af8d39ace3de437c997862af23ce6f37",
            "185fd75c358544df90551fe50ac8f3bc",
            "ff4386dd2b8e455084fe8425ba049ba2",
            "aa60c6686f564a8f879ca7c0500936fa",
            "31aada1f8fed472399aeb22257839bb1",
            "b682efb96437459594a8aa4779174105",
            "14d5aa95922f42808f9bbd525327bd14",
            "712ada05305b40608725c31f5c69354a",
            "7732c04ab0ea40f9a28e718065af4559",
            "9527c8a59a094bd2982f068dcad8fc44",
            "401b9b79069a4f3f903fb63cac214894",
            "98fde84e519047ecba21b6f381d6fa3a",
            "6bad045c1bb0489bb8b2f08b96b3b470",
            "80cef10ed0a74fbe9d4157e70d78bb5f",
            "3c2a74071fcd41d98e056abc3068b347",
            "3ce9ac8a1bb74a3a90fd0ed77465c087",
            "236a39d292fb408d85027baa2b417c81",
            "39a7bac0e96e4da38a46acb18524cb39",
            "9669c4ca5ba34c3e862405b72a283fa4",
            "1555be29872746b4b60b682299848575",
            "c9d7c48b337b4906a7aa64380204fff1",
            "0287085662d74d40b13f52549dd0b8ff",
            "81febe03b95445e09c39f3d8218b8958",
            "4afb2a617f79498bb4d00ab8f4bfcc36",
            "df1f38664c3a42b59a842faed27d245f",
            "a0743cf719734a44b8ac497caf4d3052",
            "a8bb3c9133434b3aad9130a78d9ae671",
            "bcb2fdf9c49d4ee5be537d63ead20671"
          ]
        },
        "id": "r3i4rnIhapWe",
        "outputId": "a584edae-3a94-4158-f2c5-f68f0e4af78f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3bf1419586a48e1983006db8208c2ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0a2f566eb8947b7aec4906e76e97e2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d5aa95922f42808f9bbd525327bd14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "################################################################################\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39a7bac0e96e4da38a46acb18524cb39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7fb5774e9f70>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 1it [00:00, 200.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'target': 'Windows 8', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'touchscreen functions', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
            "\n",
            "{'target': 'Windows 8', 'opinion': 'new', 'sentiment': <LabelEnum.neutral: 'NEU'>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Use pretrained SpanModel weights for prediction\n",
        "import sys\n",
        "sys.path.append(\"aste\")\n",
        "from pathlib import Path\n",
        "from data_utils import Data, Sentence, SplitEnum\n",
        "from wrapper import SpanModel\n",
        "\n",
        "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
        "    path_in = \"temp_in.txt\"\n",
        "    path_out = \"temp_out.txt\"\n",
        "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
        "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
        "    data.save_to_path(path_in)\n",
        "    model.predict(path_in, path_out)\n",
        "    data = Data.load_from_full_path(path_out)\n",
        "    return data.sentences[0]\n",
        "\n",
        "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
        "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
        "sent = predict_sentence(text, model)\n",
        "\n",
        "for t in sent.triples:\n",
        "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
        "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
        "    print()\n",
        "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "srSNwqUz-39x",
        "outputId": "9a34cc00-477f-4002-c8ec-e357284c2bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'weights_dir': PosixPath('outputs/14lap/seed_4/weights')}\n",
            "2022-11-30 03:01:13,590 - INFO - allennlp.common.params - random_seed = 4\n",
            "2022-11-30 03:01:13,592 - INFO - allennlp.common.params - numpy_seed = 4\n",
            "2022-11-30 03:01:13,596 - INFO - allennlp.common.params - pytorch_seed = 4\n",
            "2022-11-30 03:01:13,599 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
            "2022-11-30 03:01:13,600 - INFO - allennlp.common.params - type = default\n",
            "2022-11-30 03:01:13,604 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
            "2022-11-30 03:01:13,606 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-11-30 03:01:13,608 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-11-30 03:01:13,610 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-11-30 03:01:13,612 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-11-30 03:01:13,613 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-11-30 03:01:13,615 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
            "2022-11-30 03:01:13,617 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 03:01:13,618 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
            "2022-11-30 03:01:13,620 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
            "2022-11-30 03:01:13,621 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
            "2022-11-30 03:01:13,623 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
            "2022-11-30 03:01:13,625 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
            "################################################################################\n",
            "2022-11-30 03:01:13,627 - INFO - allennlp.common.params - train_data_path = /content/outputs/14lap/seed_4/temp_data/train.json\n",
            "2022-11-30 03:01:13,630 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f9692de6c90>\n",
            "2022-11-30 03:01:13,631 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2022-11-30 03:01:13,633 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2022-11-30 03:01:13,634 - INFO - allennlp.common.params - validation_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
            "2022-11-30 03:01:13,636 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2022-11-30 03:01:13,637 - INFO - allennlp.common.params - test_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
            "2022-11-30 03:01:13,639 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2022-11-30 03:01:13,640 - INFO - allennlp.common.params - batch_weight_key = \n",
            "2022-11-30 03:01:13,642 - INFO - allennlp.training.util - Reading training data from /content/outputs/14lap/seed_4/temp_data/train.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 906it [00:01, 803.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:14,774 - INFO - allennlp.training.util - Reading validation data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "reading instances: 219it [00:00, 1307.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:14,953 - INFO - allennlp.training.util - Reading test data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "reading instances: 219it [00:00, 520.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:15,382 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-11-30 03:01:15,386 - INFO - allennlp.common.params - min_count = None\n",
            "2022-11-30 03:01:15,389 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2022-11-30 03:01:15,391 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2022-11-30 03:01:15,394 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2022-11-30 03:01:15,397 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2022-11-30 03:01:15,401 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2022-11-30 03:01:15,402 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2022-11-30 03:01:15,403 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2022-11-30 03:01:15,405 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2022-11-30 03:01:15,406 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "building vocab: 1344it [00:00, 14370.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:15,504 - INFO - allennlp.common.params - model.type = span_model\n",
            "2022-11-30 03:01:15,507 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-11-30 03:01:15,513 - INFO - allennlp.common.params - model.embedder.type = basic\n",
            "2022-11-30 03:01:15,515 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
            "2022-11-30 03:01:15,517 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
            "2022-11-30 03:01:15,519 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
            "2022-11-30 03:01:15,520 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
            "2022-11-30 03:01:15,521 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
            "2022-11-30 03:01:15,523 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:15,525 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
            "2022-11-30 03:01:15,526 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
            "2022-11-30 03:01:15,653 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
            "2022-11-30 03:01:15,654 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
            "2022-11-30 03:01:15,657 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
            "2022-11-30 03:01:15,658 - INFO - allennlp.common.params - model.feature_size = 20\n",
            "2022-11-30 03:01:15,659 - INFO - allennlp.common.params - model.max_span_width = 8\n",
            "2022-11-30 03:01:15,660 - INFO - allennlp.common.params - model.target_task = relation\n",
            "2022-11-30 03:01:15,663 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
            "2022-11-30 03:01:15,665 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
            "2022-11-30 03:01:15,667 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
            "2022-11-30 03:01:15,669 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
            "2022-11-30 03:01:15,670 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
            "2022-11-30 03:01:15,672 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
            "2022-11-30 03:01:15,673 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
            "2022-11-30 03:01:15,674 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
            "2022-11-30 03:01:15,676 - INFO - allennlp.common.params - model.display_metrics = None\n",
            "2022-11-30 03:01:15,677 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
            "2022-11-30 03:01:15,678 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "2022-11-30 03:01:15,680 - INFO - allennlp.common.params - ner.regularizer = None\n",
            "2022-11-30 03:01:15,681 - INFO - allennlp.common.params - ner.name = ner_labels\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 03:01:15,687 - INFO - allennlp.common.params - relation.regularizer = None\n",
            "2022-11-30 03:01:15,688 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
            "2022-11-30 03:01:15,689 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
            "2022-11-30 03:01:15,690 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
            "2022-11-30 03:01:15,692 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
            "2022-11-30 03:01:15,693 - INFO - allennlp.common.params - relation.use_pruning = True\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f95ec5935f0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n",
            "2022-11-30 03:01:15,722 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 03:01:15,727 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,733 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,743 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,745 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 03:01:15,746 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 03:01:15,748 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 03:01:15,749 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 03:01:15,750 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 03:01:15,752 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 03:01:15,753 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,754 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,781 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,783 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
            "2022-11-30 03:01:15,787 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
            "2022-11-30 03:01:15,789 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 03:01:15,791 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 03:01:15,794 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 03:01:15,797 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 03:01:15,799 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-11-30 03:01:15,802 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
            "2022-11-30 03:01:15,806 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-11-30 03:01:15,809 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-11-30 03:01:15,811 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-11-30 03:01:15,813 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-11-30 03:01:15,815 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-11-30 03:01:15,818 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-11-30 03:01:15,820 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,822 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,823 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,824 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,829 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-11-30 03:01:15,831 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-11-30 03:01:15,832 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-11-30 03:01:15,833 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-11-30 03:01:15,834 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-11-30 03:01:15,837 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-11-30 03:01:15,838 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,839 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,841 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,844 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,845 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-11-30 03:01:15,847 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-11-30 03:01:15,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-11-30 03:01:15,857 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-11-30 03:01:15,859 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-11-30 03:01:15,862 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-11-30 03:01:15,864 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-11-30 03:01:15,868 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-11-30 03:01:15,871 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,873 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,875 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,877 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,880 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-11-30 03:01:15,882 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-11-30 03:01:15,884 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,886 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,888 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,889 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,891 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-11-30 03:01:15,893 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-11-30 03:01:15,894 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-11-30 03:01:15,896 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-11-30 03:01:15,897 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-11-30 03:01:15,899 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-11-30 03:01:15,900 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,901 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,903 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,904 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,905 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-11-30 03:01:15,906 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-11-30 03:01:15,908 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,909 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,910 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,912 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,913 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-11-30 03:01:15,915 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-11-30 03:01:15,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-11-30 03:01:15,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-11-30 03:01:15,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-11-30 03:01:15,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-11-30 03:01:15,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,926 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,928 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-11-30 03:01:15,929 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-11-30 03:01:15,930 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,931 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,933 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,934 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,935 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-11-30 03:01:15,936 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-11-30 03:01:15,937 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-11-30 03:01:15,938 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-11-30 03:01:15,940 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-11-30 03:01:15,941 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-11-30 03:01:15,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-11-30 03:01:15,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-11-30 03:01:15,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-11-30 03:01:15,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-11-30 03:01:15,958 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-11-30 03:01:15,959 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-11-30 03:01:15,960 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-11-30 03:01:15,961 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-11-30 03:01:15,963 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,964 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,965 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,967 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,968 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-11-30 03:01:15,969 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-11-30 03:01:15,970 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,972 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,973 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,974 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,976 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-11-30 03:01:15,977 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-11-30 03:01:15,978 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-11-30 03:01:15,980 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-11-30 03:01:15,981 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-11-30 03:01:15,982 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-11-30 03:01:15,983 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-11-30 03:01:15,985 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-11-30 03:01:15,986 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,987 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,989 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-11-30 03:01:15,990 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-11-30 03:01:15,991 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:15,993 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:15,994 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-11-30 03:01:15,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-11-30 03:01:15,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-11-30 03:01:15,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-11-30 03:01:15,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-11-30 03:01:16,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-11-30 03:01:16,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-11-30 03:01:16,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-11-30 03:01:16,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,006 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,007 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,008 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,010 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-11-30 03:01:16,011 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-11-30 03:01:16,012 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,014 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,015 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,016 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,018 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-11-30 03:01:16,019 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-11-30 03:01:16,020 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-11-30 03:01:16,021 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-11-30 03:01:16,022 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-11-30 03:01:16,023 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-11-30 03:01:16,024 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,025 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,026 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,028 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,029 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-11-30 03:01:16,030 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-11-30 03:01:16,031 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,033 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,034 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,035 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,037 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-11-30 03:01:16,038 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-11-30 03:01:16,039 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-11-30 03:01:16,041 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-11-30 03:01:16,042 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-11-30 03:01:16,043 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-11-30 03:01:16,045 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,046 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,047 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,049 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,050 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-11-30 03:01:16,051 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-11-30 03:01:16,052 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,054 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,055 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,056 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,058 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-11-30 03:01:16,059 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-11-30 03:01:16,060 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-11-30 03:01:16,061 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-11-30 03:01:16,063 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-11-30 03:01:16,064 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-11-30 03:01:16,065 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,067 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,068 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,069 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,070 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-11-30 03:01:16,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-11-30 03:01:16,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-11-30 03:01:16,080 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-11-30 03:01:16,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-11-30 03:01:16,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-11-30 03:01:16,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-11-30 03:01:16,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-11-30 03:01:16,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,090 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,091 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-11-30 03:01:16,093 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-11-30 03:01:16,094 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-11-30 03:01:16,095 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-11-30 03:01:16,097 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 03:01:16,098 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-11-30 03:01:16,099 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 03:01:16,100 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-11-30 03:01:16,102 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 03:01:16,103 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-11-30 03:01:16,104 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 03:01:16,105 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-11-30 03:01:16,107 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 03:01:16,108 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-11-30 03:01:16,109 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 03:01:16,111 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-11-30 03:01:16,112 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
            "2022-11-30 03:01:16,113 - INFO - filelock - Lock 140284684846864 acquired on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
            "2022-11-30 03:01:16,115 - INFO - filelock - Lock 140284684846864 released on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
            "2022-11-30 03:01:16,116 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 03:01:16,118 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 03:01:16,119 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 03:01:16,120 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 03:01:16,122 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 03:01:16,123 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 03:01:16,124 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 03:01:16,125 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 03:01:16,127 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 03:01:16,128 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 03:01:16,129 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 03:01:16,131 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 03:01:16,132 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 03:01:16,134 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 03:01:16,136 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 03:01:16,137 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 03:01:16,139 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 03:01:16,140 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 03:01:16,142 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 03:01:16,143 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 03:01:16,144 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 03:01:16,146 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 03:01:16,147 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 03:01:16,148 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 03:01:16,149 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 03:01:16,151 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 03:01:16,152 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 03:01:16,154 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 03:01:16,155 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2022-11-30 03:01:16,157 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
            "2022-11-30 03:01:16,158 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2022-11-30 03:01:16,160 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2022-11-30 03:01:16,161 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2022-11-30 03:01:16,162 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2022-11-30 03:01:16,164 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2022-11-30 03:01:16,165 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2022-11-30 03:01:16,167 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2022-11-30 03:01:16,168 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2022-11-30 03:01:16,169 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2022-11-30 03:01:16,171 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
            "2022-11-30 03:01:16,172 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
            "2022-11-30 03:01:16,173 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
            "2022-11-30 03:01:16,175 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2022-11-30 03:01:16,177 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2022-11-30 03:01:16,178 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
            "2022-11-30 03:01:16,179 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
            "2022-11-30 03:01:16,181 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2022-11-30 03:01:16,182 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
            "2022-11-30 03:01:16,184 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2022-11-30 03:01:16,185 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2022-11-30 03:01:16,186 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2022-11-30 03:01:16,188 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2022-11-30 03:01:16,189 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2022-11-30 03:01:16,191 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2022-11-30 03:01:16,192 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2022-11-30 03:01:16,194 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f9692e41190>\n",
            "2022-11-30 03:01:16,195 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2022-11-30 03:01:16,196 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2022-11-30 03:01:16,198 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2022-11-30 03:01:16,199 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2022-11-30 03:01:16,200 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2022-11-30 03:01:16,508 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
            "2022-11-30 03:01:16,518 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
            "2022-11-30 03:01:16,520 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2022-11-30 03:01:16,521 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2022-11-30 03:01:16,522 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
            "2022-11-30 03:01:16,523 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2022-11-30 03:01:16,526 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2022-11-30 03:01:16,527 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
            "2022-11-30 03:01:16,530 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
            "2022-11-30 03:01:16,531 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_relation._relation_scorers.None__relation_labels.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation.d_embedder.embedder.weight', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_relation._relation_scorers.None__relation_labels.weight'], {}\n",
            "2022-11-30 03:01:16,532 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
            "2022-11-30 03:01:16,534 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249737\n",
            "2022-11-30 03:01:16,538 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2022-11-30 03:01:16,542 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2022-11-30 03:01:16,544 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
            "2022-11-30 03:01:16,545 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
            "2022-11-30 03:01:16,547 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
            "2022-11-30 03:01:16,548 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2022-11-30 03:01:16,549 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
            "2022-11-30 03:01:16,550 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
            "2022-11-30 03:01:16,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-11-30 03:01:16,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-11-30 03:01:16,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-11-30 03:01:16,556 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-11-30 03:01:16,557 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-11-30 03:01:16,558 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-11-30 03:01:16,559 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,561 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,562 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,563 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,564 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,566 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,567 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2022-11-30 03:01:16,568 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2022-11-30 03:01:16,570 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,571 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,572 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-11-30 03:01:16,573 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-11-30 03:01:16,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-11-30 03:01:16,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-11-30 03:01:16,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-11-30 03:01:16,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-11-30 03:01:16,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,585 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2022-11-30 03:01:16,589 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2022-11-30 03:01:16,590 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,591 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,592 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-11-30 03:01:16,594 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-11-30 03:01:16,595 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-11-30 03:01:16,596 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-11-30 03:01:16,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-11-30 03:01:16,599 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-11-30 03:01:16,600 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
            "2022-11-30 03:01:16,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
            "2022-11-30 03:01:16,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-11-30 03:01:16,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-11-30 03:01:16,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-11-30 03:01:16,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-11-30 03:01:16,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-11-30 03:01:16,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-11-30 03:01:16,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,625 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,626 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,627 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,628 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
            "2022-11-30 03:01:16,629 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
            "2022-11-30 03:01:16,631 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,632 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,633 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-11-30 03:01:16,634 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-11-30 03:01:16,635 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-11-30 03:01:16,637 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-11-30 03:01:16,638 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-11-30 03:01:16,639 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-11-30 03:01:16,640 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,641 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,642 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,643 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,644 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,645 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,647 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
            "2022-11-30 03:01:16,648 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
            "2022-11-30 03:01:16,649 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,650 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,651 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-11-30 03:01:16,653 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-11-30 03:01:16,654 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-11-30 03:01:16,655 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-11-30 03:01:16,656 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-11-30 03:01:16,658 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-11-30 03:01:16,659 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,660 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,661 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,661 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,663 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,664 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,665 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
            "2022-11-30 03:01:16,666 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
            "2022-11-30 03:01:16,667 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,668 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,669 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-11-30 03:01:16,670 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-11-30 03:01:16,671 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-11-30 03:01:16,674 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-11-30 03:01:16,675 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-11-30 03:01:16,676 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-11-30 03:01:16,677 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,679 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,680 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,681 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,682 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,683 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,685 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
            "2022-11-30 03:01:16,686 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
            "2022-11-30 03:01:16,687 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,688 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,689 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-11-30 03:01:16,690 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-11-30 03:01:16,691 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-11-30 03:01:16,692 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-11-30 03:01:16,694 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-11-30 03:01:16,695 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-11-30 03:01:16,696 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,697 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,698 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,700 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,701 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,702 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,703 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
            "2022-11-30 03:01:16,705 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
            "2022-11-30 03:01:16,706 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,707 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,708 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-11-30 03:01:16,710 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-11-30 03:01:16,711 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-11-30 03:01:16,712 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-11-30 03:01:16,713 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-11-30 03:01:16,714 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-11-30 03:01:16,716 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,717 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,718 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,720 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,721 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,722 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,723 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
            "2022-11-30 03:01:16,725 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
            "2022-11-30 03:01:16,726 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,727 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,728 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-11-30 03:01:16,730 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-11-30 03:01:16,731 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-11-30 03:01:16,732 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-11-30 03:01:16,733 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-11-30 03:01:16,735 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-11-30 03:01:16,736 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,737 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,738 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,740 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,741 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,742 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,744 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
            "2022-11-30 03:01:16,746 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
            "2022-11-30 03:01:16,747 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,748 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,749 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-11-30 03:01:16,751 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-11-30 03:01:16,752 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-11-30 03:01:16,753 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-11-30 03:01:16,754 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-11-30 03:01:16,756 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-11-30 03:01:16,757 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,758 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,760 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,761 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,762 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,763 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,765 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
            "2022-11-30 03:01:16,766 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
            "2022-11-30 03:01:16,767 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,836 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,837 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-11-30 03:01:16,839 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-11-30 03:01:16,840 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-11-30 03:01:16,841 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-11-30 03:01:16,842 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-11-30 03:01:16,844 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-11-30 03:01:16,845 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-11-30 03:01:16,846 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-11-30 03:01:16,848 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,849 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,850 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-11-30 03:01:16,859 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-11-30 03:01:16,893 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
            "2022-11-30 03:01:16,895 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
            "2022-11-30 03:01:16,898 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-11-30 03:01:16,900 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-11-30 03:01:16,902 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
            "2022-11-30 03:01:16,904 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
            "2022-11-30 03:01:16,906 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
            "2022-11-30 03:01:16,907 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
            "2022-11-30 03:01:16,910 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
            "2022-11-30 03:01:16,912 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
            "2022-11-30 03:01:16,913 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
            "2022-11-30 03:01:16,914 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
            "2022-11-30 03:01:16,915 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
            "2022-11-30 03:01:16,917 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
            "2022-11-30 03:01:16,919 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
            "2022-11-30 03:01:16,920 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
            "2022-11-30 03:01:16,922 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
            "2022-11-30 03:01:16,926 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
            "2022-11-30 03:01:16,928 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
            "2022-11-30 03:01:16,929 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
            "2022-11-30 03:01:16,932 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
            "2022-11-30 03:01:16,933 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
            "2022-11-30 03:01:16,935 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
            "2022-11-30 03:01:16,936 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
            "2022-11-30 03:01:16,941 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
            "2022-11-30 03:01:16,942 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
            "2022-11-30 03:01:16,943 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
            "2022-11-30 03:01:16,945 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
            "2022-11-30 03:01:16,946 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
            "2022-11-30 03:01:16,948 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
            "2022-11-30 03:01:16,949 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2022-11-30 03:01:16,950 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2022-11-30 03:01:16,951 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2022-11-30 03:01:16,952 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2022-11-30 03:01:16,954 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2022-11-30 03:01:16,955 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2022-11-30 03:01:16,967 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2022-11-30 03:01:16,968 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2022-11-30 03:01:16,969 - INFO - allennlp.training.trainer - Epoch 0/9\n",
            "2022-11-30 03:01:16,971 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
            "2022-11-30 03:01:16,972 - INFO - allennlp.training.trainer - GPU 0 memory usage: 844M\n",
            "2022-11-30 03:01:16,974 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/906 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:01:17,437 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.0735, MEAN__relation_recall: 0.0541, MEAN__relation_f1: 0.0623, batch_loss: 4.1855, loss: 19.9654 ||: 100%|##########| 906/906 [01:29<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:02:47,332 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.8919, MEAN__relation_recall: 0.0957, MEAN__relation_f1: 0.1728, batch_loss: 3.4678, loss: 9.2253 ||: 100%|##########| 219/219 [00:05<00:00, 40.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:02:52,748 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 03:02:52,752 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.062  |     0.173\n",
            "2022-11-30 03:02:52,759 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.073  |     0.892\n",
            "2022-11-30 03:02:52,762 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.054  |     0.096\n",
            "2022-11-30 03:02:52,764 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.330  |     0.716\n",
            "2022-11-30 03:02:52,768 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.320  |     0.707\n",
            "2022-11-30 03:02:52,770 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.340  |     0.725\n",
            "2022-11-30 03:02:52,772 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.330  |     0.716\n",
            "2022-11-30 03:02:52,774 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.320  |     0.707\n",
            "2022-11-30 03:02:52,776 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.340  |     0.725\n",
            "2022-11-30 03:02:52,778 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.062  |     0.173\n",
            "2022-11-30 03:02:52,780 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.073  |     0.892\n",
            "2022-11-30 03:02:52,782 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.054  |     0.096\n",
            "2022-11-30 03:02:52,784 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   843.606  |       N/A\n",
            "2022-11-30 03:02:52,785 - INFO - allennlp.training.tensorboard_writer - loss                      |    19.965  |     9.225\n",
            "2022-11-30 03:02:52,787 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4127.316  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:02:55,895 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 03:02:57,626 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.656161\n",
            "2022-11-30 03:02:57,632 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:05\n",
            "2022-11-30 03:02:57,636 - INFO - allennlp.training.trainer - Epoch 1/9\n",
            "2022-11-30 03:02:57,639 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-11-30 03:02:57,644 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 03:02:57,649 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.4882, MEAN__relation_recall: 0.3404, MEAN__relation_f1: 0.4011, batch_loss: 10.0549, loss: 9.5514 ||: 100%|##########| 906/906 [01:28<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:04:27,788 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.7639, MEAN__relation_recall: 0.1594, MEAN__relation_f1: 0.2638, batch_loss: 8.5782, loss: 8.9333 ||: 100%|##########| 219/219 [00:05<00:00, 43.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:04:32,879 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 03:04:32,881 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.401  |     0.264\n",
            "2022-11-30 03:04:32,884 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.488  |     0.764\n",
            "2022-11-30 03:04:32,889 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.340  |     0.159\n",
            "2022-11-30 03:04:32,895 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.754  |     0.784\n",
            "2022-11-30 03:04:32,897 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.777  |     0.775\n",
            "2022-11-30 03:04:32,900 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.732  |     0.793\n",
            "2022-11-30 03:04:32,905 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.754  |     0.784\n",
            "2022-11-30 03:04:32,907 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.777  |     0.775\n",
            "2022-11-30 03:04:32,910 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.732  |     0.793\n",
            "2022-11-30 03:04:32,913 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.401  |     0.264\n",
            "2022-11-30 03:04:32,918 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.488  |     0.764\n",
            "2022-11-30 03:04:32,923 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.340  |     0.159\n",
            "2022-11-30 03:04:32,950 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 03:04:32,952 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.551  |     8.933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:04:32,962 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4215.652  |       N/A\n",
            "2022-11-30 03:04:36,059 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 03:04:38,109 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.472822\n",
            "2022-11-30 03:04:38,110 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:24\n",
            "2022-11-30 03:04:38,116 - INFO - allennlp.training.trainer - Epoch 2/9\n",
            "2022-11-30 03:04:38,120 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-11-30 03:04:38,123 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 03:04:38,129 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6161, MEAN__relation_recall: 0.5089, MEAN__relation_f1: 0.5574, batch_loss: 1.6394, loss: 7.2603 ||: 100%|##########| 906/906 [01:28<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:06:07,972 - INFO - allennlp.training.trainer - Validating\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.6667, MEAN__relation_recall: 0.4058, MEAN__relation_f1: 0.5045, batch_loss: 5.9121, loss: 12.1476 ||: 100%|##########| 219/219 [00:05<00:00, 42.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:06:13,133 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
            "2022-11-30 03:06:13,139 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.557  |     0.505\n",
            "2022-11-30 03:06:13,141 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.616  |     0.667\n",
            "2022-11-30 03:06:13,144 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.509  |     0.406\n",
            "2022-11-30 03:06:13,147 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.860  |     0.796\n",
            "2022-11-30 03:06:13,149 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.879  |     0.795\n",
            "2022-11-30 03:06:13,152 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.842  |     0.797\n",
            "2022-11-30 03:06:13,155 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.860  |     0.796\n",
            "2022-11-30 03:06:13,158 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.879  |     0.795\n",
            "2022-11-30 03:06:13,160 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.842  |     0.797\n",
            "2022-11-30 03:06:13,164 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.557  |     0.505\n",
            "2022-11-30 03:06:13,169 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.616  |     0.667\n",
            "2022-11-30 03:06:13,172 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.509  |     0.406\n",
            "2022-11-30 03:06:13,182 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
            "2022-11-30 03:06:13,189 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.260  |    12.148\n",
            "2022-11-30 03:06:13,192 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4215.652  |       N/A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-30 03:06:16,292 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
            "2022-11-30 03:06:18,593 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.476870\n",
            "2022-11-30 03:06:18,596 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:43\n",
            "2022-11-30 03:06:18,599 - INFO - allennlp.training.trainer - Epoch 3/9\n",
            "2022-11-30 03:06:18,601 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
            "2022-11-30 03:06:18,604 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
            "2022-11-30 03:06:18,608 - INFO - allennlp.training.trainer - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MEAN__relation_precision: 0.7126, MEAN__relation_recall: 0.6330, MEAN__relation_f1: 0.6704, batch_loss: 11.1852, loss: 4.8294 ||:  14%|#3        | 126/906 [00:11<01:12, 10.76it/s]"
          ]
        }
      ],
      "source": [
        "# Train SpanModel from scratch\n",
        "random_seed = 4\n",
        "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
        "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
        "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
        "\n",
        "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
        "model.fit(path_train, path_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjyiKWjSF7oZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7475f09-d593-48a9-a708-da3186dd575a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "################################################################################\n",
            "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
            "{'locals': ('span_extractor_type', 'endpoint')}\n",
            "{'locals': ('use_span_width_embeds', True)}\n",
            "{'ner_loss_fn': CrossEntropyLoss()}\n",
            "{'unused_keys': dict_keys([])}\n",
            "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f26de145f80>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
            "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
            "{'relation_loss_fn': CrossEntropyLoss()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading instances: 328it [00:00, 802.08it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"path_pred\": \"pred.txt\",\n",
            "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
            "  \"precision\": 0.658695652173913,\n",
            "  \"recall\": 0.5580110497237569,\n",
            "  \"score\": 0.6041874376869392\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate SpanModel F1 Score\n",
        "import json\n",
        "\n",
        "path_pred = \"pred.txt\"\n",
        "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
        "model.predict(path_in=path_test, path_out=path_pred)\n",
        "results = model.score(path_pred, path_test)\n",
        "print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3bf1419586a48e1983006db8208c2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2964524130442869889ae7d4b66cbde",
              "IPY_MODEL_fe16020d5dd44eee9c31f35dbcbbb121",
              "IPY_MODEL_ea885b58cd6f4dada54fa30787c1c6ca"
            ],
            "layout": "IPY_MODEL_068f7a5d5f124ef289ea37d778909b56"
          }
        },
        "b2964524130442869889ae7d4b66cbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71315cce26594e529e387c0f4106fca6",
            "placeholder": "​",
            "style": "IPY_MODEL_7d8159fb6e1b4eed9064bd27b00cb167",
            "value": "Downloading: 100%"
          }
        },
        "fe16020d5dd44eee9c31f35dbcbbb121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36cd33348e4e43e197142e37b0be18b7",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7630128ce13c4bb7bc32015deee09ba9",
            "value": 433
          }
        },
        "ea885b58cd6f4dada54fa30787c1c6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa655d553e6440c8b21c4935dd0d6a1c",
            "placeholder": "​",
            "style": "IPY_MODEL_c59edc717c184afd8e32e39f5578ba09",
            "value": " 433/433 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "068f7a5d5f124ef289ea37d778909b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71315cce26594e529e387c0f4106fca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8159fb6e1b4eed9064bd27b00cb167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36cd33348e4e43e197142e37b0be18b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7630128ce13c4bb7bc32015deee09ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa655d553e6440c8b21c4935dd0d6a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59edc717c184afd8e32e39f5578ba09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0a2f566eb8947b7aec4906e76e97e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05943317ad6548cd80b4ff1b335b77fa",
              "IPY_MODEL_10256154352b4d3ca51e60bb807646ab",
              "IPY_MODEL_cf8bfe8d68334a8fac6a57ee6b61a0c0"
            ],
            "layout": "IPY_MODEL_32a6466b31eb4782a25cbc1195c8fb2d"
          }
        },
        "05943317ad6548cd80b4ff1b335b77fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8d39ace3de437c997862af23ce6f37",
            "placeholder": "​",
            "style": "IPY_MODEL_185fd75c358544df90551fe50ac8f3bc",
            "value": "Downloading: 100%"
          }
        },
        "10256154352b4d3ca51e60bb807646ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff4386dd2b8e455084fe8425ba049ba2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa60c6686f564a8f879ca7c0500936fa",
            "value": 231508
          }
        },
        "cf8bfe8d68334a8fac6a57ee6b61a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31aada1f8fed472399aeb22257839bb1",
            "placeholder": "​",
            "style": "IPY_MODEL_b682efb96437459594a8aa4779174105",
            "value": " 232k/232k [00:00&lt;00:00, 212kB/s]"
          }
        },
        "32a6466b31eb4782a25cbc1195c8fb2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8d39ace3de437c997862af23ce6f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185fd75c358544df90551fe50ac8f3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff4386dd2b8e455084fe8425ba049ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa60c6686f564a8f879ca7c0500936fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31aada1f8fed472399aeb22257839bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b682efb96437459594a8aa4779174105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d5aa95922f42808f9bbd525327bd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_712ada05305b40608725c31f5c69354a",
              "IPY_MODEL_7732c04ab0ea40f9a28e718065af4559",
              "IPY_MODEL_9527c8a59a094bd2982f068dcad8fc44"
            ],
            "layout": "IPY_MODEL_401b9b79069a4f3f903fb63cac214894"
          }
        },
        "712ada05305b40608725c31f5c69354a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98fde84e519047ecba21b6f381d6fa3a",
            "placeholder": "​",
            "style": "IPY_MODEL_6bad045c1bb0489bb8b2f08b96b3b470",
            "value": "Downloading: 100%"
          }
        },
        "7732c04ab0ea40f9a28e718065af4559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cef10ed0a74fbe9d4157e70d78bb5f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c2a74071fcd41d98e056abc3068b347",
            "value": 466062
          }
        },
        "9527c8a59a094bd2982f068dcad8fc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce9ac8a1bb74a3a90fd0ed77465c087",
            "placeholder": "​",
            "style": "IPY_MODEL_236a39d292fb408d85027baa2b417c81",
            "value": " 466k/466k [00:00&lt;00:00, 393kB/s]"
          }
        },
        "401b9b79069a4f3f903fb63cac214894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fde84e519047ecba21b6f381d6fa3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bad045c1bb0489bb8b2f08b96b3b470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80cef10ed0a74fbe9d4157e70d78bb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2a74071fcd41d98e056abc3068b347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ce9ac8a1bb74a3a90fd0ed77465c087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236a39d292fb408d85027baa2b417c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a7bac0e96e4da38a46acb18524cb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9669c4ca5ba34c3e862405b72a283fa4",
              "IPY_MODEL_1555be29872746b4b60b682299848575",
              "IPY_MODEL_c9d7c48b337b4906a7aa64380204fff1"
            ],
            "layout": "IPY_MODEL_0287085662d74d40b13f52549dd0b8ff"
          }
        },
        "9669c4ca5ba34c3e862405b72a283fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81febe03b95445e09c39f3d8218b8958",
            "placeholder": "​",
            "style": "IPY_MODEL_4afb2a617f79498bb4d00ab8f4bfcc36",
            "value": "Downloading: 100%"
          }
        },
        "1555be29872746b4b60b682299848575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1f38664c3a42b59a842faed27d245f",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0743cf719734a44b8ac497caf4d3052",
            "value": 440473133
          }
        },
        "c9d7c48b337b4906a7aa64380204fff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8bb3c9133434b3aad9130a78d9ae671",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb2fdf9c49d4ee5be537d63ead20671",
            "value": " 440M/440M [00:07&lt;00:00, 74.5MB/s]"
          }
        },
        "0287085662d74d40b13f52549dd0b8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81febe03b95445e09c39f3d8218b8958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4afb2a617f79498bb4d00ab8f4bfcc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1f38664c3a42b59a842faed27d245f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0743cf719734a44b8ac497caf4d3052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8bb3c9133434b3aad9130a78d9ae671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb2fdf9c49d4ee5be537d63ead20671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}